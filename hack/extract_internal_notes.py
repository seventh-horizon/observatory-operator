#!/usr/bin/env python3
import argparse, re, sys, pathlib, textwrap, datetime

# File globs to scan
GLOBS = ["**/*.go", "**/*.ts", "**/*.tsx", "**/*.js", "**/*.jsx", "**/*.yaml", "**/*.yml"]

# Heuristics: treat a comment block as "verbose" if it has >= MIN_LINES
# or contains one of these “teaching/explanatory” keywords.
MIN_LINES = 3
KEYWORDS = [
    r"\bwhy\b", r"\bhow\b", r"\bnote\b", r"\bremember\b", r"\bfor example\b",
    r"\bmeaning\b", r"\bexplains?\b", r"\bbecause\b", r"\bcontext\b",
    r"\bintention\b", r"\brationale\b", r"\bgotcha\b", r"\bcareful\b",
]

# Simple language-aware comment tokens
LANG = {
    ".go":   {"line": r"//", "block_start": r"/\*", "block_end": r"\*/"},
    ".ts":   {"line": r"//", "block_start": r"/\*", "block_end": r"\*/"},
    ".tsx":  {"line": r"//", "block_start": r"/\*", "block_end": r"\*/"},
    ".js":   {"line": r"//", "block_start": r"/\*", "block_end": r"\*/"},
    ".jsx":  {"line": r"//", "block_start": r"/\*", "block_end": r"\*/"},
    ".yaml": {"line": r"#",  "block_start": None,   "block_end": None},
    ".yml":  {"line": r"#",  "block_start": None,   "block_end": None},
}

def looks_verbose(text_lines):
    joined = "\n".join(text_lines).lower()
    if len(text_lines) >= MIN_LINES:
        return True
    return any(re.search(kw, joined) for kw in KEYWORDS)

def extract_blocks(path: pathlib.Path):
    ext = path.suffix.lower()
    spec = LANG.get(ext)
    if not spec:
        return []

    src = path.read_text(encoding="utf-8", errors="ignore").splitlines()
    blocks = []

    line_token = spec["line"]
    bs, be = spec["block_start"], spec["block_end"]

    i = 0
    while i < len(src):
        line = src[i]
        # Block comments /* ... */
        if bs and re.search(rf"^\s*{bs}", line):
            start = i
            buf = [line]
            i += 1
            while i < len(src):
                buf.append(src[i])
                if re.search(rf"{be}\s*$", src[i]):
                    break
                i += 1
            end = i
            # strip /* */ markers for content
            content = "\n".join(buf)
            content_stripped = re.sub(rf"^\s*{bs}", "", buf[0]).rstrip()
            inner = [content_stripped] + [b for b in buf[1:-1]] + [re.sub(rf"{be}\s*$","",buf[-1])]
            block = {"start": start, "end": end, "lines": buf, "inner": inner, "kind": "block"}
            if looks_verbose([s.lstrip("/* ").rstrip("*/ ") for s in inner]):
                blocks.append(block)
            i += 1
            continue

        # Line comments //... or #...
        if line_token and re.search(rf"^\s*{line_token}", line):
            start = i
            buf = [line]
            i += 1
            while i < len(src) and re.search(rf"^\s*{line_token}", src[i]):
                buf.append(src[i])
                i += 1
            inner = [re.sub(rf"^\s*{line_token}\s?", "", l) for l in buf]
            block = {"start": start, "end": i-1, "lines": buf, "inner": inner, "kind": "line"}
            if looks_verbose(inner):
                blocks.append(block)
            continue

        i += 1

    return blocks

def shorten_one_liner(inner_lines):
    text = " ".join(l.strip() for l in inner_lines)
    text = re.sub(r"\s+", " ", text).strip()
    # Take first sentence-ish
    m = re.match(r"(.{0,160}?[\.\!\?])\s", text + " ")
    return (m.group(1) if m else text[:160]).strip()

def main():
    p = argparse.ArgumentParser(description="Extract verbose/teaching comments to docs/DEV_GUIDE.md")
    p.add_argument("--inplace", action="store_true", help="Replace long comments in source with a short pointer")
    p.add_argument("--root", default=".", help="Repo root (default: .)")
    p.add_argument("--out", default="docs/DEV_GUIDE.md", help="Output docs path")
    args = p.parse_args()

    root = pathlib.Path(args.root).resolve()
    out_path = root / args.out
    out_path.parent.mkdir(parents=True, exist_ok=True)

    found = []
    for glob in GLOBS:
        for path in root.glob(glob):
            # Skip generated or vendor if present
            s = str(path)
            if any(seg in s for seg in ["/vendor/", "/.git/", "/bin/", "/dist/"]):
                continue
            if not path.is_file():
                continue
            blocks = extract_blocks(path)
            if blocks:
                found.append((path, blocks))

    # Build docs content
    header = f"""# Developer Guide — extracted internal notes

_This file was generated by `hack/extract_internal_notes.py` on {datetime.datetime.utcnow().isoformat()}Z._

These entries centralize verbose “teaching/explanatory” comments so code can remain concise.

---
"""
    sections = [header]
    for path, blocks in found:
        rel = path.relative_to(root)
        for b in blocks:
            anchor = f"{rel}#L{b['start']+1}-L{b['end']+1}".replace("/", "-").lower()
            snippet = "\n".join(b["inner"]).rstrip()
            sections.append(f"## `{rel}` L{b['start']+1}–L{b['end']+1}\n\n```text\n{snippet}\n```\n")

    out_path.write_text("\n".join(sections), encoding="utf-8")
    print(f"Wrote {out_path} with {sum(len(b) for _, b in found)} extracted block(s).")

    if not args.inplace:
        print("\n(no source files modified — run with --inplace to replace long comments by pointers)")
        return

    # In-place replacement: swap the long comment for a one-liner + pointer to docs
    for path, blocks in found:
        src_lines = path.read_text(encoding="utf-8", errors="ignore").splitlines()
        # apply from bottom to top so indices remain valid
        for b in sorted(blocks, key=lambda x: x["start"], reverse=True):
            rel = path.relative_to(root)
            one = shorten_one_liner(b["inner"])
            placeholder = f"{one} — see docs/DEV_GUIDE.md (`{rel}` L{b['start']+1}–L{b['end']+1})."
            ext = path.suffix.lower()
            t = LANG.get(ext, {})
            line_tok = t.get("line", "//")

            if b["kind"] == "line":
                new_block = [re.sub(rf"^\s*{line_tok}\s?.*$", f"{line_tok} {placeholder}", src_lines[b["start"]])]
                src_lines[b["start"]:b["end"]+1] = new_block
            else:
                # block comment -> single line comment
                src_lines[b["start"]:b["end"]+1] = [f"{line_tok} {placeholder}"]

        backup = path.with_suffix(path.suffix + ".bak.internal-notes")
        backup.write_text("\n".join(src_lines) + "\n", encoding="utf-8")
        path.write_text("\n".join(src_lines) + "\n", encoding="utf-8")
        print(f"Updated {path} (backup at {backup})")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        sys.exit(130)